<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: stack-based | Language Perils]]></title>
  <link href="http://ncreep.github.io/language_perils/blog/categories/stack-based/atom.xml" rel="self"/>
  <link href="http://ncreep.github.io/language_perils/"/>
  <updated>2014-04-08T23:17:07+03:00</updated>
  <id>http://ncreep.github.io/language_perils/</id>
  <author>
    <name><![CDATA[Daniel Beskin]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[State of Joy]]></title>
    <link href="http://ncreep.github.io/language_perils/blog/2014-03-19-state-of-joy.html"/>
    <updated>2014-03-19T01:54:19+02:00</updated>
    <id>http://ncreep.github.io/language_perils/blog/state-of-joy</id>
    <content type="html"><![CDATA[Having finished with [binary trees](/blog/2013-04-21-joyous-tree-friends.html) and getting somewhat sidetracked by [metaprogramming](/blog/2013-05-24-meta-joy.html), we are now ready for our next small project. Implementing binary trees was sort of a warm-up for getting used to Joy - now I would like to do something a bit less textbooky. 

As you may recall, Joy has a very flexible syntax due to its homoiconicity (as can be seen in the metaprogramming post). Having a flexible syntax should make a language easily amenable to embedding of [domain-specific languages](http://en.wikipedia.org/wiki/Domain-specific_language) (DSLs). Personally, I'm a big fan of DSLs, so trying to implement one in Joy seems like a nice idea for a small project.

In order to actually have a domain-specific language, we first need to come up with a domain. Having gone through a careful process of examining and comparing various domains (i.e., choosing the first thing that randomly came up in my mind at some distant point in time), I decided to model [state machines](http://en.wikipedia.org/wiki/State_machine). More specifically, I'll be implementing a small language that can describe state machines augmented by a stack, which makes it a [pushdown automaton](http://en.wikipedia.org/wiki/Pushdown_automaton). Adding a stack to our machine seems like a natural idea for a stack-based language and also makes the domain a tad more interesting; we'll see how that works out later on.

<!-- more -->

(For the more pedantically inclined, what we'll implement will actually have access to the whole stack and to the whole of Joy's stack-manipulation power, so strictly speaking it's going to be something more powerful than a pushdown automaton, but we won't linger on that point.)

Before we get to our state machine DSL, we'll write some code that can evaluate state machines, which will give us a better understanding of our domain; let us get to that. 

A state machine is simply a list of states with their corresponding transition functions. The transition functions take the current input and, depending on its value and the current stack, decide what the next state is. In our implementation, a state will be a list pair, where the first item is the value of the state, e.g., its name, and the second is the state transition function. To make this more obvious in the code, we'll define their corresponding accessors:

```
state-value == 0 at # fetch the state value
next-state == 1 at # fetch the transition function
```

(All code for this post can be found in [this folder](https://github.com/ncreep/language_perils/tree/master/Joy/state_machine), the main code for the state machine implementation is in [state_machine.joy](https://github.com/ncreep/language_perils/blob/master/Joy/state_machine/state_machine.joy))

The core part of our state machine evaluation process is this function:

```
# runs a state against an input list: input state stack -> final-state-value
run-state-from-stack == 
  swap # arguments are now: input stack state
  [finish-state-run] [popd popd state-value] [
    [move-first] dip
    next-state i # input [stack value] -> input new-stack new-state
  ] tailrec;
```

It takes a list of inputs, an initial state, and a stack (which is just a list that we'll treat as a stack). It then runs the state machine against the inputs while maintaining the stack in the background. The whole thing works by recursively evaluating the current transition function against the current input and stack; the recursion is made anonymous by using the `tailrec` combinator. Let's break down the definition:

* We swap the arguments to have them in the right order for our recursive step.
* We check whether we are done (i.e., there's no more input) with the `finish-state-run` function.
* If so, we throw out all our arguments and pick out the current state value.
* Otherwise, we pair up our current input (the first item in the input list) and the current stack using the `move-first` function.
* Using the `i` combinator, we evaluate the transition function against the input/stack pair.
* The output of the transition function is the next state; at this point we recurse and start all over.

And that's all we need to evaluate a state machine. To see that it actually works, let's code up a concrete state machine. Apart from actually demonstrating what we've done thus far, this will also be helpful in the design of our DSL. It may so happen that what we already have is close enough to our domain, and we won't have a need for a special language. That being very unlikely, at the very least we may get some pointers to what aspects of our syntax we should optimize to get closer to the domain.

*(cue the narrator)*

>Family is important, and as programmers, we should strive to help other programmers deal with realistic scenarios that come up in family life. In this installment of our "Family for Geeks", we'll see how to deal with babies.

*(fading out with happy jingle music)*

So, we'll implement a state machine that totally realistically models the behavior of a typical baby. Our baby has a number of possible states: sleepy, hungry, asleep, and crying. Obviously, the last one is the most common. Our main goal is to choose the right action to get the baby to fall asleep. We have a number of actions that we can do with the baby; these are the inputs to the state machine: sing a lullaby, feed, and soothe. To make this more realistic, our baby is going to ~~be vindictive~~ have a memory. The baby is going to keep count for every time we mess up and choose a wrong action. Once we've messed up too many times, the baby is going to call a social worker. Calling a social worker will be counted as yet another state of a baby. Here is our baby's behavior described by a table:

<pre id="baby-table">
             || sleepy | hungry | asleep |          crying            | call social worker |
============================================================================================
sing lullaby || asleep | crying | crying | should call social worker? | call social worker |
        feed || crying | asleep | crying | should call social worker? | call social worker |
      soothe || crying | crying | crying |          asleep            | call social worker |
</pre>

The header row contains the possible states of the baby; the first column has the possible actions. For every state/action pair, we choose the baby's next state. Getting the baby into the crying state is considered wrong, and we'll use the stack to keep track of the number of wrongs. If we get the baby into the asleep state, we get to decrement our wrongs count. Once the baby is in the crying state, we check whether the baby was wronged too many times ("should call social worker?"). If so, we move to the call social worker state (which is pretty much game over in this state machine). Otherwise, we keep on crying.

This sums up the behavior of a typical baby in a completely life-like fashion. Now, we can try and write it down as real code (which can be found in [baby_state_machine.joy](https://github.com/ncreep/language_perils/blob/master/Joy/state_machine/baby_state_machine.joy)):

<div id="baby-states">
```
sleepy == ["sleepy" [[
  [["sing-lullaby" input-is] right asleep]
  [["feed" input-is] wrong crying]
  [["soothe" input-is] wrong crying]
] condn]];
  
hungry == ["hungry" [[
  [["sing-lullaby" input-is] wrong crying]
  [["feed" input-is] right asleep]
  [["soothe" input-is] wrong crying]
] condn]];
  
asleep == ["asleep" [[
  [["sing-lullaby" input-is] wrong crying]
  [["feed" input-is] wrong crying]
  [["soothe" input-is] wrong crying]
] condn]];
  
crying == ["crying" [[
  [["sing-lullaby" input-is] should-call-social-worker]
  [["feed" input-is] should-call-social-worker]
  [["soothe" input-is] right asleep]
] condn]];

call-social-worker == ["call-social-worker" [cur-stack call-social-worker]];
```
</div>

Well, that sucked... If you squint hard enough, you may recognize our state machine from before, but there's a whole lot of noise obscuring it from us. 

As you can see, every state gets its own top-level definition. The first bit of the state is just its name as a string. Next comes the state transition function in the form of a conditional `condn`, which is just like the built-in `cond` (which acts like a multi-branch `if` expression) but does not require a default case. Every line corresponds to one possible input. The `input-is` function checks the current input against the string; if it matches, we execute the following code. Because our input is part of an input/stack pair, the `input-is` function has to break it down to fetch out the input from the pair and only then compare it to the input in the current branch. 

The code that we execute after choosing a branch works against the input/stack pair and must produce a new stack value and a new state as a result. In most cases, we need to decide whether the action is wrong or right and increment/decrement the stack, then we choose the next state. For this purpose, we use one of either `wrong` or `right`:
```
wrong == [succ] on-stack;
right == [pred] on-stack;

# [stack value] func -> new-stack
on-stack  == swap cur-stack uncons [swap i] dip cons;
```

The `on-stack` combinator takes a piece of code and executes it against the top value of the current stack. It takes care of splitting out the stack from the input/stack pair (using `cur-stack`) and applying a function to its top value. The `wrong` and `right` functions just pass the `succ` (increment) or `pred` (decrement) to the `on-stack` combinator to achieve the required effect.

For example, the line `[["feed" input-is] wrong crying]` checks whether the input is `feed`; if so, the action was wrong, and we increment the counter and move on to the `crying` state.

In the case where we need to check whether a social worker should be called, we invoke `should-call-social-worker`:
```
should-call-social-worker == 
  [cur-stack first max-mistakes >=] 
  [cur-stack call-social-worker] 
  [wrong crying] ifte
```

This checks whether the counter on the top of the stack went past our mistake limit; if so, it leaves the stack as is (`cur-stack`) and chooses the `call-social-worker` state. Otherwise, we invoke the `wrong` function and stay in the `crying` state.

The `call-social-worker` state is trivial and just keeps the stack as is, without moving to another state.

We can now spot some patterns of repetitiveness that, hopefully, our DSL will be able to eradicate. Firstly, we are repeating our state names both as their definition name and their string name in the state value. Secondly, the list of possible inputs is repeated in almost all of the states. Lastly, manipulating the stack is rather explicit; every function we want to invoke on the stack has to be wrapped in an `on-stack` combinator, and even if we don't need anything on the stack at all, we still have to mention it with the `cur-stack` function. You'd expect to be able to achieve something more transparent than that from a stack-based language.

All that aside, we can actually execute our state machine with the following code:

```
["soothe"] sleepy run-baby-state # => "crying"
["soothe" "feed" "sing-lullaby" "feed"] sleepy run-baby-state # => "call-social-worker"
```

The first argument is the input list, the second is the state we start from.  
So at least it works as expected.

This concludes the exposition of the domain, in the next installment we'll try to come up with an actual language specific to it.]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Meta-Joy]]></title>
    <link href="http://ncreep.github.io/language_perils/blog/2013-05-24-meta-joy.html"/>
    <updated>2013-05-24T14:34:00+03:00</updated>
    <id>http://ncreep.github.io/language_perils/blog/meta-joy</id>
    <content type="html"><![CDATA[In the [previous post](/blog/2013-04-21-joyous-tree-friends.html) I was struggling with the noise generated in my code by stack manipulation-related functions. Having reached a dead end, I promised you a shiny new direction, which I'll be introducing in this post.

To do that, we'll have to recap one of the Joy basics, namely, its homoiconicity. In the [introduction](/blog/2013-03-18-the-joy-of-joy.html), I mentioned how Joy's list primitive is actually a quoted program; this should be familiar if you're acquainted with Lisp lists. So... we can easily go meta on the language by employing list manipulation. Here's a simple example to illustrate the point:
```
[1 2] [+] concat i # => 3
```

<!-- more -->

(`i` evaluates the list as a program)

As a real program may be an arbitrarily nested list, manipulating it won't be that simple. Say I want to turn this piece of code `[1 [2 3 +] *]` into `[1 [2 3 *] *]`. I can do this manually like so:
```
[1 [2 3 +] *] dup
1 at         # => [2 3 +]
2 take       # => [2 3]
[*] concat   # => [2 3 *]
1 insert-at. # => [1 [2 3 *] *]
```
(which assumes the availability of the `insert-at` function we were messing about with the last time)

And obviously, this approach is too clumsy to scale up to any real use case. What we need is some generic way to find and replace bits of lists with other bits. To do this, I'll introduce yet another step in the meta direction. In the standard library, we have the `name` function, which takes a symbol, e.g. a non-literal item in a list, and returns its name as a string, like so:
```
[foo bar baz] [name] map # => ["foo" "bar" "baz"]
```

Armed with this function, we can treat quoted programs as lists of strings, and do any sort of string manipulation we may want with it (we also have the inverse of `name` - `intern`, which takes a string and returns a symbol). And how is this useful in our quest for list manipulation nirvana? It means that we can treat finding and replacing of program parts as finding and replacing (splicing) strings in a list, and that's a rather down-to-earth non-meta operation.

Inspired by Lisp macros, I decided to implement a splicing scheme illustrated by this example:
```
["two" "four" "five"] [[1 ~0 3] [~1 ~2] concat] splice-from-list # => [[1 "two" 3] ["four" "five"] concat]
```

The first list is the argument list and the second is the target program skeleton. Each `~X` symbol is treated as an index `X` in the argument list. Upon application of the `splice-from-list` function, each occurrence of the `~X` pattern is replaced by the corresponding item in the argument list.

The code for the implementation is in the [repository](https://github.com/ncreep/language_perils) in the [meta.joy](https://github.com/ncreep/language_perils/blob/master/Joy/meta_joy/meta.joy) file; let's look at it:
```
splice-from-list == [ 
	[is-num-splice-pattern] 
	[splice-to-num at] 
	[]
	ifte
] treemap popd;
```

The function `treemap` does most of the heavy lifting. `treemap` takes a tree (which is an arbitrarily nested list where each non-list value is treated as a leaf) and applies a given function to each leaf; it is rather simple to implement using the built-in `treerec` combinator. In our case, the tree is the program skeleton, its symbols are the leaves and the function to be applied is the `ifte`  expression. The `ifte`  expression checks whether a symbol matches the splicing pattern (`is-num-splice-pattern`). If it does, the `ifte`  expression converts it to a number (`splice-to-num`) and fetches the corresponding list item, otherwise, it leaves it as is. It's in the `is-num-splice-pattern` and `splice-to-num` functions that we apply our ability to treat symbols as text.

It is important to note that the `~X` patterns don't have any special significance in Joy; they are just valid identifiers. Trying to evaluate a piece of code that contains them without any replacement will probably result in an error, as they won't have any predefined meaning.

Because we are after a more convenient way to write functions, a more likely scenario is to splice values directly from the stack, so we have
```
splice-from-stack ==  swap [take-from-stack] dip splice-from-list;
```

where `take-from-stack` takes a fixed number of items from the stack and places them in a list. Now we can write
```
"two" "four" "five" [[1 ~0 3] [~1 ~2] concat] 3 splice-from-stack # => [[1 "two" 3] ["four" "five"] concat]
```
Note how the `"two" "four" "five"` items are on the stack and not in a list. In most cases, it may feel redundant to write the number of items to take from the stack, it is evident from the maximal value of `X` in the different `~X` patterns, so we define
```
splice-from-stack-max == [max-splice-num 1 +] nullary splice-from-stack;
```
And the final product:
```
splice == splice-from-stack-max i;
```

which actually evaluates the resulting program, as in
```
"two" "four" "five" [[1 ~0 3] [~1 ~2] concat] splice # => [1 "two" 3 "four" "five"]
```

Now we are ready for a first attempt at rewriting the `insert-at` function from the [previous post](/blog/2013-04-21-joyous-tree-friends.html) using our cool new metaprogramming techniques. First, let's recall the original function:

```
# inserts an item at a given position, deleting the previous item: list val index -> list
insert-at == 
	swapd dupd dup swapd
	take rollup
	1 + drop
	enconcat;
```

And here's the new version:
```
insert-at == [
	~1
	~0 ~2 take
	~0 ~2 1 + drop
	enconcat
] splice;
```

Success! We have no stack primitives visible in the code. But... I'm not quite satisfied with the fact that the function arguments don't have explicit names. You see, I have this issue, I like naming things: variables, functions, babies, you name it. I mean, I name it, that is, I will name it once you give me the thing. As Joy is devoid of either variables or babies, the only thing left to name is functions, and the only way to do this is to include them in a top level `DEFINE`, so we can't have function-local definitions (something along the lines of Lisp's `let` definitions). 

Splicing to the rescue. Instead of splicing from a list (or the stack), we can do the splicing from a map, like so:
```
[[four "four"] [two "two"] [five "f" "ive" concat]] 
[four  [1 two 3] [five 6 7] enconcat]
splice-from-map # => [1 "two" 3 "four" "f" "ive" concat 6 7]
```

The first nested list is treated as a map where each entry is another list. In each entry, the first symbol is treated as a key and the rest as the value. The second list is the program skeleton, where we replace every occurrence of a symbol that appears in the map with the value it is mapped to. The corresponding implementation:
```
splice-from-map == [ 
	[key-in-map] 
	[find-by-key] 
	[]
	ifte
] treemap-concat popd i;
```
which is quite similar to `splice-from-list`. Instead of looking for `~X` patterns, we look for items that appear in our map. Instead of fetching from a list, we fetch from a map. The last difference is that instead of mapping with `treemap` we use `treemap-concat`, which maps a function that takes a leaf and results in a list merged into the tree instead of the original leaf. The reason we need that is to be able to use multiple symbols as values in the map (like `"f" "ive" concat` in the example). The implementation of `treemap-concat` was a bit tricky to get right at 4 a.m., I'll leave the figuring out how it works as an exercise.

To slightly simplify the usage of `splice-from-map`, we'll allow to join the map and program skeleton into a single list, as in:
```
[[[plus +] 
  [square dup *]] 
  3 2 plus square		  
 ] let-map # => 25
```

The definition of `let-map`:
```
let-map ==  [first] [rest] cleave splice-from-map;
```

And now we have a simple implementation of local definitions. To make this more usable in the context of naming function arguments, we'll compose this with stack splicing:
```
let == splice-from-stack-max let-map;
```

Using `let` we can rewrite the `insert-at` function as:
```
insert-at == [
    [[list ~0] [val ~1] [index ~2]]
    	val
    	list index take
    	list index 1 + drop
    	enconcat
] let;
```

The combination of list and map splicing acts somewhat like named arguments in regular languages. It is definitely more explicit than the previous version, but I find it a bit clumsy to write. In simple cases where we only need items from the stack without any transformations, we can use this function:
```
let-splice == [first list-to-splice] [rest] cleave cons let;
```

Instead of taking a map like `let`, it takes a list of symbols and converts the list into a map where the symbols are the keywords and consecutive `~X` patterns are the values (`list-to-splice`). With this, we arrive at our final version of `insert-at`:
```
insert-at == [
    [list val index]
    	val
    	list index take
    	list index 1 + drop
    	enconcat
] let-splice;
```
The first line of the definition declares the arguments, saying: "I'll need three arguments from the stack, and I'll be using these names for them". `let-splice` does the magic of figuring out the mapping between the arguments and the values on the stack. This syntax is less flexible than `let`, as we can only name values from the stack and not any other expression. But I think it works well in this example, yielding the most readable code thus far.

As you may remember, but probably don't, this whole quest for stack manipulation cleansing started out with my wish to write a readable version of the `build-tree-with-value` function, which traverses a tree looking for a value and uses a pair of functions to handle success or failure. In pseudocode it looked like this:
```
build-tree-with-value == [
    [ [empty-tree] [empty-handler] ]
    [ [value =] [value-handler] ]
    
    [ [value <] [set-left-tree-for-recursion] [insert-new-left-tree] ]
    [           [set-right-tree-for-recursion] [insert-new-right-tree] ]
] condlinrec
```

And to remind you of the atrocity you had to go through last time, heeere's Johnny:
```
build-tree-with-value == rollup swap [
	[ [empty-tree] [rolldown dup 0 at rollupd i] ]
	[ [value =] [rolldown dup 1 at rollupd i] ]
		
	[ [value <] [dup left-tree rollupd] [swapd insert-left] ]
	[           [dup right-tree rollupd] [swapd insert-right] ]
] condlinrec popd
``` 

You can open your eyes now, I won't be doing that again. Can our new meta-power-tools help us alleviate the pain? It so happens that yes, they definitely can. Here's Johnny reformed:
```
build-tree-with-value == [ 
	[val empty-handler val-handler] [
		[ [empty-tree]  [val empty-handler i] ]
		[ [value val =] [val val-handler i] ]
		
		[ [value val >] [_left-tree] [insert-left] ]
		[           	[_right-tree] [insert-right] ]
] condlinrec] let-splice;
```

The original algorithm was slightly modified to make this more readable. Namely, the value being searched for is not passed around - it is wired into the skeleton of the code; this affects the signature of the handler functions, which is now `tree value -> tree`. It also inverts the comparison sign in the last predicate. The full new implementation can be found [here](https://github.com/ncreep/language_perils/blob/master/Joy/bin_tree/Trees2.joy). 

I actually wasn't expecting that much similarity to the pseudocode, I wrote it long before I had a readable version of `build-tree-with-value`. And what's more important is that we are using a generic solution, not something tailor-made for this particular problem. Another thing I quite like about this solution is how natural it was to build it in incremental steps: write a function, compose it with another one to refine it, rinse and repeat. That's a general property of Joy (and probably any other concatenative language), making it easy to write simple, bite-size pieces of code.

Now, one might expect me to go OCD on the rest of my binary tree implementation, and prune out as much of the remaining stack manipulation bits as possible, but I won't be doing that. No, seriously, not going to bother, I'm totally fine with how it is...

There are some reservations about my meta solution, though. First off, the implementation is far from being complete. The `let`/`splice` expressions cannot be properly nested in all cases, e.g.:
```
[[[a 2]] [[[a 3]] a 4 *] let] let # => 9
[[[a dup dup]] [[[a pop]] 4 a] let] let # => 4
```

And you can't make a definition and use it in the same map, so this is not valid:
```
[[[a dup] [b a pop]] 4 b] let
```

Bearing in mind that the whole implementation is ~70 LOC (no, that's not a leftover splicing pattern, and no, I'm not using a Joy-based templating engine), that's probably not so bad. Fixing these issues shouldn't be too complicated, but what we have should suffice as a proof of concept.

A completely different issue is performance related, though performance is of little significance to me in this case; it seems that using this kind of meta-programming really stresses out the GC. Running the new tree implementation on the usual Joy interpreter (the one you're likely to compile if you're fetching it from the [Joy site](http://www.kevinalbrecht.com/code/joy-mirror/joy.html), it has "NOBDW" in its title) crashes when trying to insert around 4 items. To circumvent the problem, I used the Joy interpreter compiled with the BDW GC (there's a special `make` file for that purpose). This fixes the issue, and you can easily insert more than 100 items in either implementation, though the meta-programming implementation is still considerably slower.

But the most important issue, in my opinion, is that it feels as if I'm trying to shoehorn my approach to programming into Joy's. In this whole exercise, I'm essentially trying to emulate named function arguments, which is one of the things that Joy seems to purposefully avoid. My feeling is that there must exist somewhere "The Joy Way (TM)", which would allow me to achieve the same level of readability without resorting to metaprogramming tricks. On the other hand, the fact that it was that simple to achieve this goal might be an indicator that maybe this approach was not an act of complete heresy. Any insight on this issue will be greatly appreciated.

Anyways, this concludes our excursion into the green lands of meta-trees. Stay tuned for the next time.]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Joyous Tree Friends]]></title>
    <link href="http://ncreep.github.io/language_perils/blog/2013-04-21-joyous-tree-friends.html"/>
    <updated>2013-04-21T18:15:00+03:00</updated>
    <id>http://ncreep.github.io/language_perils/blog/joyous-tree-friends</id>
    <content type="html"><![CDATA[Having introduced Joy in the [previous post](/blog/2013-03-18-the-joy-of-joy.html), as per our [grand scheme of things](/blog/2013-03-18-introduction.html), we are now ready for some coding.


As a first small project, I decided to try and implement a simple [binary search tree](http://en.wikipedia.org/wiki/Binary_search_tree). Nothing fancy, no self-balancing or anything [evil like that](http://j.rigelseven.com/read/67201/). Just your Plain Old Binary Search Tree (which can be handily abbreviated as POBST).

The reason for this boring textbook example is twofold. First, Joy being, for me, a rather new way of thinking about code, I didn't want to distract myself with something overly creative. Having a ready recipe for the thing I want to code provides me with a nice distraction-free, Joyful coding experience. Second, as Joy stresses function-level programming (no values and all that), I was wondering how a data structure, which I think of as a value, would look like in this paradigm.

<!-- more -->

(Source code for this post is in the [repository](https://github.com/ncreep/language_perils/blob/master/Joy/bin_tree/Trees.joy)).

First thing first, we need to have some representation of our tree. Now, we are quite far from our cozy OO land, mind you; we don't even have simple structs in Joy. So this is your typical "we're not in Kansas anymore" situation.  
The omnipresent lists to the rescue. As we remember (or not), lists in Joy are heterogeneous, so we can stuff anything in them, including other lists, which fits well with the recursive nature of trees.

So for our tree, we'll use a list with three elements - the first is the value, the second is the left subtree, and the third is the right subtree. All parts are optional. A couple of examples:

An empty tree
```
[]
```

A tree with a single node
```
[8 [] []]
```

And this tree 

<img class="center" src="/images/joy/simple_tree.png">

is

```
[8 [2 [1 [] []] [5 [] []]] [10 [] [12 [] []]]]
```

Untangled all the brackets? Great, we can move on.

In view of how simple the tree representation is, the second reason for implementing binary trees kind of evaporates, oh well...

The [full source code](https://github.com/ncreep/language_perils/blob/master/Joy/bin_tree/Trees.joy) should be documented enough to be, in most parts, fairly readable; so I won't be explaining it step by step here. The final result is rather boring, e.g., we can create and query a tree like this:
```
new-tree [4 8 6 1 3 6 4 3 4 9] add-all 3 tree-contains # => true
```
(Note that, due to what I think is a bug in the interpreter, when adding a large number of items at a time, say 100, sometimes the interpreter either crashes or gives unexpected errors.)

No surprises here. But there are some interesting implementation details that are actually worth a discussion; we are getting to them below.

Having implemented getters (in a moment, we'll see `value`, which extracts the value of a tree node), setters (as our trees are immutable, setters, or any mutating operations, actually produce new trees) and some predicates for the tree parts, I am getting to the interesting bits: adding and removing elements from the tree.

Adding an item to the tree is a simple recursive operation: traverse the tree till you find the right place, insert a new node with the value there. In case the item is already present, do nothing. Joy being Joy, we have a combinator that makes this possible without writing an explicitly recursive function. In this case, we use `condlinrec` (see [manual](http://www.kevinalbrecht.com/code/joy-mirror/html-manual.html)), which performs linear recursion, but unlike `linrec` it can check for multiple conditions before the recursion step or stopping.

A skeleton for the adding function looks like something like this:
```
add-val == [
    [ [empty-tree] [create-new-tree-with-the-value] ]
    [ [value =] [do-nothing] ]
    
    [ [value <] [set-left-tree-for-recursion] [insert-new-left-tree] ]
    [ [set-right-tree-for-recursion] [insert-new-right-tree] ]
] condlinrec
```

It's not that difficult to fill in the pseudocode bits, but we won't be doing that; instead, let's see what the deleting function should look like. In pseudocode:
```
delete-val == [
    [ [empty-tree] [do-nothing] ]
    [ [value =] [create-a-new-tree-without-the-value] ]
    
    [ [value <] [set-left-tree-for-recursion] [insert-new-left-tree] ]
    [ [set-right-tree-for-recursion] [insert-new-right-tree] ]
] condlinrec
```

Hmm, rather similar, in both cases we are rebuilding the tree according to some value; the differences occur when we actually get to the value or when it's missing. Being conscientious programmers, we cannot let this code duplication be. The code must be WET (which is like DRY, but more suitable for trees), and we must find a way to hydrate it. 

Simple enough, this is a functional language; we can pass the appropriate handler functions as parameters and let them take care of the differences, while keeping common code intact:
```
build-tree-with-value == [
    [ [empty-tree] [empty-handler] ]
    [ [value =] [value-handler] ]
    
    [ [value <] [set-left-tree-for-recursion] [insert-new-left-tree] ]
    [ [set-right-tree-for-recursion] [insert-new-right-tree] ]
] condlinrec

add-val == [[do-nothing] [create-new-tree-with-the-value]] build-tree-with-value
delete-val == [[create-a-new-tree-without-the-value] [do-nothing]] build-tree-with-value
```

Great, we got ourselves WET with Joy, done; we can now move on to greener pastures.  
Well, of course not, that was just pseudocode, we actually need an implementation for this thing. And here it is:
```
build-tree-with-value == rollup swap [
	[ [empty-tree] [rolldown dup 0 at rollupd i] ]
	[ [value =] [rolldown dup 1 at rollupd i] ]
		
	[ [value <] [dup left-tree rollupd] [swapd insert-left] ]
	[ [dup right-tree rollupd] [swapd insert-right] ]
] condlinrec popd

add-val == [[pop [[] []] cons] [popd]] build-tree-with-value;
delete-val == [[popd] [popd delete-tree]] build-tree-with-value
```
Bugger me - I can't quite read this, and I wrote that not that long ago.  
So why is it so complicated? In the pseudocode above, I elided any references to argument handling; I just assumed the arguments to be there when needed. That's quite natural for someone coming from a background of [value-level](http://en.wikipedia.org/wiki/Value-level_programming) programming languages. When you write a function, e.g., in Java, arguments to functions are just there, available, without any fuss, by their name. Not so when you're dealing with a stack-based language; here, the arguments are implied to be on the stack, and they have no names. To be able to use them, you have to make sure that they are properly ordered on the top of the stack.

Back to our code. First, we have the easy bits; `add-val` and `delete-val` are actually quite similar to our pseudocode. They assume that a tree and a value to be added/removed are on top of the stack, each of them pushes their pair of handling functions onto the top of the stack, and passes control to `build-tree-with-value`.  
The handler functions are rather simple; to figure them out, we need to remember that when we apply them we have the tree on the top of the stack and the value below it. After the application, we need to leave only the new tree and nothing else. I'll leave the figuring out as an exercise to the reader (oh how I hate when people do that. At last, the oh so sweet revenge...).

Now, `build-tree-with-value` creates a function that takes three arguments: a tree, a value, and a list with a pair of handler functions; in that order, i.e. the handler functions are on the top of the stack. But we don't want them that way, what we need is: handlers, value, tree. That's what the first `rollup swap` functions do. After applying them, we are ready for the recursion. And that's the last point where I can still explain the code without taking out a piece of paper and drawing many little stacks on it. As you can see, each condition is followed by a bunch of stack-manipulating functions, the whole purpose of which is to tweak the stack so that the arguments are in the right order, multiplicity and are ready for the further recursive calls. A horrid, horrid piece of code.

I would love to give the explanation of this code to you, the reader, as another exercise, but that would be just plain sadistic. And I won't be bothered to explain it myself, that would be way too tedious, boring and quite meaningless. Why meaningless? Because by now, I think that it's pretty clear that we are doing something wrong. To quote a [comment](http://www.codecommit.com/blog/cat/the-joy-of-concatenative-languages-part-1#comment-4407) from the [The Joy of Concatenative Languages](http://www.codecommit.com/blog/cat/the-joy-of-concatenative-languages-part-1) series
>If you find you need to be continually aware of the stack, then, plain and simple, "You're Doing It Wrong."

We need to step back and see how we can alleviate the stack manipulation problem. To do that, we'll examine a simpler case: the `insert-at` function. This function takes a list, a value and an index, and inserts the value at the specified position in the list. The algorithm we'll be implementing is:

* take the first N - 1 items from the list (prefix)
* take the tail of list starting from the N + 1th item (tail)
* concatenate the prefix value and tail.

Simple enough, especially as we already have the `take`, `drop` and `enconcat` functions implemented for us. And here's my first naive attempt at an implementation:
```
insert-at == 
	swapd dupd dup swapd
	take rollup
	1 + drop
	enconcat;
```
Not the horrors of `build-tree-with-value`, but still far from satisfactory; we cannot, by any means, plead ignorance of the stack.  
For the sport of it, let's try to follow the definition. 

* We start out with `list val index` (the rightmost item is the top of the stack). 
* The first line rearranges it, so that we have `val list index list index`. 
* The second line applies the `take` function to the top two items and pushes the result down the stack, so we have `val prefix list index`.
* The third line calculates the tail of the list, leaving `val prefix tail`.
* The last line performs the concatenation of all three items on the stack, and we are done.

Now, our aim is to reduce the amount of stack related operations we see at each stage. To do this, I tried looking at the different functions and combinators available in Joy. But being a novice, I couldn't find anything simple that makes the code much better. What I managed to figure out is that part of the complexity stems from the fact that in order to reuse an argument, I have to duplicate it on the stack, which requires even more manipulation of the stack. One of the combinators that I found, `nullary`, allows to use a function without removing its arguments from the stack, so one can avoid the duplication in that case. Here's the best that I managed:
```
insert-at == 
	swapd 
	[take] nullary rollup
	1 + drop
	enconcat;
```
The steps are as follows:

* `list val index` -> `val list index`
* `val list index` -> `val list index prefix` -> `val prefix list index`
* `val prefix list index` -> `val prefix tail`
* Concatenating the last three items.

A definite improvement, but I still don't see it as a satisfactory result. The second line seems rather cryptic to me. Further investigation in this direction did not yield anything better, so I decided to leave it at that. 

If there are any Joy or concatenative gurus reading this, I would love to hear your opinion on how this code can be improved.

After abandoning this direction, I had another idea. I will leave it till the next post in the series. But the upshot of it is that I was able to write the following code:
```
insert-at == [
	~1
	~0 ~2 take
	~0 ~2 1 + drop
	enconcat
] 3 splice-from-stack;
```
Ignoring the surrounding `splice-from-stack` call, we've managed to remove all stack related manipulation. The cost, so it seems, is that we introduced something that looks like custom syntax.

[To be continued](/blog/2013-05-24-meta-joy.html)...
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Joy of Joy]]></title>
    <link href="http://ncreep.github.io/language_perils/blog/2013-03-18-the-joy-of-joy.html"/>
    <updated>2013-03-18T06:21:00+02:00</updated>
    <id>http://ncreep.github.io/language_perils/blog/the-joy-of-joy</id>
    <content type="html"><![CDATA[**Intro**: `[swap  dip  dup  dip  pop]  dip  dup  dip  pop`  
(sing aloud accompanied by a Jazz trio or even *a cappella*)

Anyways, this is actual Joy source code, taken from the [Mathematical foundations of Joy](http://www.kevinalbrecht.com/code/joy-mirror/j02maf.html) article. No, really, you're not squinting hard enough, there is some actual math there. 

Well, this is my first language from the [Perlis Languages](http://blog.fogus.me/2011/08/14/perlis-languages/) list.  It's a concatenative language, colloquially known as a stack-based language (not sure what sort of person goes all colloquial about anything concatenative, probably the sort of person that uses the word "colloquial"). Stack-based languages tend to have very little in the sense of syntax, one may even call them "Lisp without the parentheses". So that makes Joy a good candidate to be the first language for this little project; it's rather simple and self-contained.  You can pretty much get all the material you might need to tackle Joy from the (mirror of) the [official site](http://www.kevinalbrecht.com/code/joy-mirror/joy.html). Other than that, as recommended by Fogus, there's the really nice "[The Joy of Concatenative Languages](http://www.codecommit.com/blog/category/cat)" series by [Daniel Spiewak](http://www.codecommit.com); although his language of choice is Cat, it still is, as usual for Daniel's writings, a very instructive and fun read.

Let's take a quick tour of Joy, though for a proper introduction you should consult the [official one](http://www.kevinalbrecht.com/code/joy-mirror/j01tut.html). 
 
<!-- more -->
 
To the eyes of a conventional programmer, the first thing that stands out in a stack-based language is the Reverse Polish notation. 
```
3 4 + 5 *
```
(Note that to actually evaluate the snippet in the Joy interpreter, you'll need to put a period at the end, as in `3 4 + 5 * .`, but I'll be omitting it here).

The above happens to be 35. And that obviously screams at you with the horrid unnaturalness of the out-of-order operators. Of course, the average programmer, being to some extent a form of a humanoid, expects this to be written infix as in:
```
3 + 4 * 5
```
Wait, that's actually 23. Of course I meant to write:
```
(3 + 4) * 5
```
Now it's all natural and pleasing to the eye. And that's the last time in the Joy series that you'll be seeing anything written infix, get used to it, sorry...

Actually, there's a whole thing based around RPN having no precedence issues; it allows one to compose programs (functions) by just *concatenating* their sources - no need to worry about any missing parentheses. And that's why you call them *concatenative* languages; the stack is actually an optional implementation detail.  
Having crossed the RPN chasm, we can continue to some Joy basics.

We've already seen number literals and arithmetic operators. We also have the usual boolean values `true` and `false`; string literals are written in double quotes, and characters are prefixed with a single quote. So the following snippet yields `true`:
```
"abcd" 1 at 'b equal
```
Now I'll pretend that you know practically nothing about stacks and explain this snippet step by step. Having done that, I'll assume that by some miracle, you are now fluent in everything stack, and I wouldn't be bothered to give any more accounts of the source at such level of detail. Ready? Here we go:  
The first word pushes `"abcd"` onto the stack; the second `1`. `at` looks at the last two things on the stack and treats the top one as a (zero based) index and the one below it as a string (or a list, we'll get to those in a bit). It then pops them off and leaves on top the character at the indexed position, in our case `'b`. Next we push another `'b` onto the top of the stack and test the equality of the top two items on the stack with `equal`, popping them off and pushing the result (`true`) onto the top.

Feeling fluent now? Great, moving on...

Next we have list literals, written in square brackets, so this yields 3:
```
[1 2 3 4 5] 2 at
```
Lists are heterogeneous and can contain anything, so this `[1 'c 2 "abc" [1 2 3] 5]` is a valid list.

Set literals can be written in curly brackets, as in `{1 2 3}`, but they can only contain "small integers", so I didn't really have any use for them further down the road (too bad you can't plug in other implementations into this syntax, oh well...).

There is also a whole array of stack manipulation functions, such as swapping and duplicating items on the stack. So the following yields the square of 4:
```
4 dup *  # => 16
```
(The hash sign designates a comment)

**Interlude**: `[[dup  dip  pop]  dip]  dip  swap  dip  dup  dip  pop`

Now come the interesting bits - the lists introduced above are not plain lists, they are quoted programs (think Lisp lists). This means that the list `[4 dup *]` is actually a value representing the program above; it can be passed around and evaluated at will. Evaluation is accomplished via *combinators*. These take quoted programs as input and use them to calculate new values.  
The simplest combinator is `i`; it just evaluates (unquotes) the quoted program at the top of the stack, like this:
```
[4 dup *] i # => 16
```

Let's look at a slightly more interesting example. The combinator `map` takes a quoted program and applies it to the elements of a list:
```
[1 2 3 4] [dup *] map # => [1 4 9 16]
```
The above is one of the most common use cases for higher order functions, so we got that topic covered.

By now, you might've noticed the conspicuous lack of control structures, guess what, these are also implemented with combinators. The standard `if then else` form looks like:
```
1500 [1000 >]  [2 /]  [3 *]  ifte  # => 750
```
The first list is the condition, which is checked against the top of the stack (in this case 1500). If the condition is met, we apply the second quote to the top of the stack, otherwise the third.  
It takes a little time to get used to this sort of syntax, but after you get it, there's a whole world of flexibility here...

The last type of combinators we'll look at are recursive combinators. These allow one to create recursive functions using anonymous recursion. The most basic recursive combinator is `linrec`, which performs linear recursion. The textbook example for linear recursion is the factorial, implementing it with `linrec` we get
```
[null]  [succ]  [dup pred]  [*]  linrec
```

The first quote is the `if` part, it checks for the base case (here, whether the current argument is 0). The second quote is the `then` part, which is executed when we reach the base case (here, when we reach 0, we take its successor, 1, and leave it on the stack). The last two quotes are the `else1` and `else2` parts. The first is executed before we take the recursive step; in here we duplicate the argument and take the predecessor of the copy. The second quote is executed after the recursion step, in this case we multiply the top two items on the stack. To sum up, we are recursively filling up the stack with the numbers from the given argument down to 1, then, when we back up, we are multiplying them in pairs leaving the result on top all the time, until we reach the original value. The last multiplication step gives us the value of the factorial at the top of the stack.

I found combinators to be my biggest stumbling block on the path to readability - when looking at a new combinator, you really haven't a chance of figuring out its purpose unless its name is very obvious or you have its documentation at hand. Take this for example:
```
[1]  [*]  primrec
```
Can you guess what that function does? It happens to be the very same factorial function from before, implemented with a specialized version of `linrec`; it wasn't that obvious to me...  
As you know, with great flexibility come great code obfuscation powers. But also, great DSL powers, and I really like DSLs, so overall, I'm sure the whole combinators thing works out fine.

There are plenty more useful functions and combinators; you can see the whole standard library [here](http://www.kevinalbrecht.com/code/joy-mirror/html-manual.html).

The last bit of syntax I left out are definitions; you can actually give names to stuff in Joy. So if we wanted to name our square and factorial functions, we could do it like so:
```
DEFINE 
   square == dup *;
   factorial == [1]  [*]  primrec.
```
And use it like so:
```
4 square # => 16
5 factorial # => 120
```
There are also some modularization/information hiding facilities built in, but I won't be using them here, so moving right along.

This sums up my not so brief but definitely incomplete introduction to Joy. The most glaring thing I glossed over is the mathematical foundations of Joy. It so happens that Joy is a function-level programming language, in the sense that there are no values in the language, just functions. No, `42` is not a value, `42` is a function that takes a stack and returns a new stack with the value `42` on top. So without noticing it, all along we've been composing functions and not just that - we've been using point-free style while at it.  
Although I didn't delve deep into the maths myself, its presence definitely makes me feel better. I like it when a language is well thought through; such elegance can only come from math.

All together now:  
**Outro**: `[dup dip pop]  dip  dup  dip  pop`
]]></content>
  </entry>
  
</feed>
